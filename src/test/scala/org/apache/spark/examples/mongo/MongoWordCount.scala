package org.apache.spark.examples.mongo

import org.apache.hadoop.conf.Configuration
import org.apache.spark.SparkContext._
import org.apache.spark.examples.AbstractSparkExample
import org.apache.spark.rdd.RDD
import org.bson.{BSONObject, BasicBSONObject}

/**
 * MongoDB에 있는 beowulf.input 정보를 읽어, 단어 빈도수를 계산하여 beowulf.output 에 저장합니다.
 * 먼저 mongodb에 data/mongo/beowulf.input 에 정보를 입력해야 합니다.
 *
 * $ mongoimport -d beowulf -c input beowulf.json
 *
 * @author sunghyouk.bae@gmail.com at 15. 3. 4.
 */
class MongoWordCount extends AbstractSparkExample {

  sparkTest("Mongo Word Count") {
    val hadoopCfg = new Configuration()
    hadoopCfg.set("mongo.input.uri", "mongodb://127.0.0.1:27017/beowulf.input")
    hadoopCfg.set("mongo.output.uri", "mongodb://127.0.0.1:27017/beowulf.output")

    val mongoRDD: RDD[(Object, BSONObject)] = sc.newAPIHadoopRDD(hadoopCfg,
                                                                  classOf[com.mongodb.hadoop.MongoInputFormat],
                                                                  classOf[Object],
                                                                  classOf[BSONObject])

    // Input contains tuples of (ObjectId, BSONObject)
    val countsRDD: RDD[(String, Int)] = mongoRDD.flatMap {
      arg =>
        arg._2.get("text").toString.toLowerCase.replaceAll("[.,!?\n]", " ").split(" ")
    }
                                        .map(word => (word, 1))
                                        .reduceByKey(_ + _)
                                        .sortByKey()

    // Output contains tuples of (null, BSONObject) - ObjectId will be generated by Mongo driver if null
    val saveRDD = countsRDD.map { tuple =>
      val bson = new BasicBSONObject()
      bson.put("word", tuple._1)
      bson.put("count", tuple._2)
      (null, bson)
    }

    // Only MongoOutputFormat and config are relevant
    saveRDD.saveAsNewAPIHadoopFile("file:///bogus",
                                    classOf[Any],
                                    classOf[Any],
                                    classOf[com.mongodb.hadoop.MongoOutputFormat[Any, Any]],
                                    hadoopCfg)

  }

}
